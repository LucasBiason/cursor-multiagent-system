# devops - padr√µes e boas pr√°ticas

**√∫ltima atualiza√ß√£o:** 2025-12-08  
**aplic√°vel a:** todos os projetos com deploy

---

## docker e docker-compose

### estrutura b√°sica

```yaml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - API_KEY=${API_KEY}
    volumes:
      - ./backend:/app
    depends_on:
      - db
  
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### secrets em .env

```bash
# docker-compose.yml
environment:
  - API_KEY=${API_KEY}

# .env (gitignored)
API_KEY=sk-1234567890abcdef
```

### nunca hardcodar secrets

```yaml
# ‚ùå errado
environment:
  - API_KEY=sk-1234567890abcdef

# ‚úÖ correto
environment:
  - API_KEY=${API_KEY}
```

---

## dockerfile - a base de tudo

### estrutura otimizada

um dockerfile bem feito √© r√°pido de build, pequeno em tamanho, e seguro:

```dockerfile
# Use imagem base oficial e espec√≠fica (n√£o latest)
FROM python:3.11-slim

# Metadados (opcional mas √∫til)
LABEL maintainer="seu-email@example.com"
LABEL description="API FastAPI para processamento de dados"

# Vari√°veis de ambiente
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Criar usu√°rio n√£o-root (seguran√ßa)
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Diret√≥rio de trabalho
WORKDIR /app

# Copiar apenas requirements primeiro (cache layer)
COPY requirements.txt .

# Instalar depend√™ncias
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo da aplica√ß√£o
COPY . .

# Mudar ownership para usu√°rio n√£o-root
RUN chown -R appuser:appuser /app

# Mudar para usu√°rio n√£o-root
USER appuser

# Expor porta
EXPOSE 8000

# Healthcheck (importante para orquestra√ß√£o)
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Entrypoint (ver se√ß√£o espec√≠fica)
ENTRYPOINT ["./entrypoint.sh"]

# Comando padr√£o
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### por que n√£o root?

executar containers como root √© perigoso. se algu√©m conseguir explorar uma vulnerabilidade, ter√° acesso root no container:

```dockerfile
# ‚ùå perigoso
USER root
CMD ["python", "app.py"]

# ‚úÖ seguro
RUN groupadd -r appuser && useradd -r -g appuser appuser
USER appuser
CMD ["python", "app.py"]
```

### multi-stage builds

para aplica√ß√µes que precisam compilar c√≥digo, use multi-stage builds:

```dockerfile
# Stage 1: Build
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Stage 2: Production
FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY package*.json ./
RUN npm ci --production
CMD ["node", "dist/index.js"]
```

isso resulta em imagens muito menores, porque voc√™ n√£o inclui ferramentas de build na imagem final.

---

## docker compose - orquestra√ß√£o de servi√ßos

### estrutura completa

docker compose √© onde a m√°gica acontece. voc√™ define todos os servi√ßos, redes, volumes e depend√™ncias em um arquivo:

```yaml
version: '3.8'

services:
  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        - BUILD_ENV=production
    container_name: myapp-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    env_file:
      - .env
      - .env.local  # Sobrescreve .env se existir
    volumes:
      - ./backend:/app
      - backend_static:/app/staticfiles
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Database
  db:
    image: postgres:15-alpine
    container_name: myapp-db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    container_name: myapp-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Nginx (reverse proxy)
  nginx:
    image: nginx:alpine
    container_name: myapp-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - backend_static:/static:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
    networks:
      - app-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  backend_static:
    driver: local

networks:
  app-network:
    driver: bridge
```

### por que healthchecks?

healthchecks permitem que o docker saiba quando um servi√ßo est√° realmente pronto:

```yaml
# Sem healthcheck - depende_on s√≥ espera container iniciar
depends_on:
  - db  # Pode iniciar antes do banco estar pronto!

# Com healthcheck - espera at√© estar saud√°vel
depends_on:
  db:
    condition: service_healthy  # Espera healthcheck passar
```

### vari√°veis de ambiente

nunca hardcode secrets. use vari√°veis de ambiente:

```yaml
# ‚ùå nunca fazer
environment:
  - DATABASE_PASSWORD=senha123

# ‚úÖ sempre fazer
environment:
  - DATABASE_PASSWORD=${DB_PASSWORD}

# Ou melhor ainda, usar env_file
env_file:
  - .env
```

### .env file

crie um `.env.example` para documentar vari√°veis necess√°rias:

```bash
# .env.example
DATABASE_URL=postgresql://user:password@db:5432/mydb
REDIS_URL=redis://redis:6379/0
SECRET_KEY=change-me-in-production
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1

# .env (gitignored)
# Copie .env.example e preencha com valores reais
```

---

## entrypoint - inicializa√ß√£o inteligente

### por que entrypoint?

entrypoint √© o script que roda quando o container inicia. ele √© perfeito para:
- aguardar depend√™ncias ficarem prontas
- rodar migrations
- criar diret√≥rios necess√°rios
- validar configura√ß√µes

### entrypoint b√°sico

```bash
#!/bin/bash
set -e  # Exit on error

echo "üöÄ Starting application..."

# Aguardar banco de dados ficar pronto
echo "‚è≥ Waiting for database..."
until pg_isready -h db -U ${DB_USER} -d ${DB_NAME}; do
  echo "Database is unavailable - sleeping"
  sleep 2
done
echo "‚úÖ Database is ready!"

# Rodar migrations
echo "üì¶ Running migrations..."
python manage.py migrate --noinput

# Coletar arquivos est√°ticos
echo "üìÅ Collecting static files..."
python manage.py collectstatic --noinput

# Criar superuser se n√£o existir (apenas em dev)
if [ "$CREATE_SUPERUSER" = "true" ]; then
  echo "üë§ Creating superuser..."
  python manage.py shell << EOF
from django.contrib.auth import get_user_model
User = get_user_model()
if not User.objects.filter(username='admin').exists():
    User.objects.create_superuser('admin', 'admin@example.com', 'admin123')
EOF
fi

# Executar comando passado (CMD do Dockerfile)
echo "‚úÖ Starting application..."
exec "$@"
```

### entrypoint avan√ßado

para aplica√ß√µes mais complexas:

```bash
#!/bin/bash
set -e

# Fun√ß√£o para log
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

# Fun√ß√£o para aguardar servi√ßo
wait_for_service() {
    local host=$1
    local port=$2
    local service=$3
    
    log "‚è≥ Waiting for $service at $host:$port..."
    until nc -z $host $port; do
        log "$service is unavailable - sleeping"
        sleep 2
    done
    log "‚úÖ $service is ready!"
}

# Aguardar depend√™ncias
wait_for_service db 5432 "PostgreSQL"
wait_for_service redis 6379 "Redis"

# Validar vari√°veis de ambiente cr√≠ticas
if [ -z "$SECRET_KEY" ]; then
    log "‚ùå ERROR: SECRET_KEY not set"
    exit 1
fi

# Rodar migrations apenas se necess√°rio
if [ "$RUN_MIGRATIONS" = "true" ]; then
    log "üì¶ Running migrations..."
    python manage.py migrate --noinput
fi

# Coletar est√°ticos apenas em produ√ß√£o
if [ "$ENVIRONMENT" = "production" ]; then
    log "üìÅ Collecting static files..."
    python manage.py collectstatic --noinput
fi

# Healthcheck script
if [ "$1" = "healthcheck" ]; then
    python -c "import requests; requests.get('http://localhost:8000/health')"
    exit $?
fi

# Executar comando
log "‚úÖ Starting application..."
exec "$@"
```

### tornar entrypoint execut√°vel

no dockerfile:

```dockerfile
# Copiar entrypoint
COPY entrypoint.sh /app/entrypoint.sh

# Tornar execut√°vel
RUN chmod +x /app/entrypoint.sh

# Usar como entrypoint
ENTRYPOINT ["/app/entrypoint.sh"]
```

---

## makefile - automa√ß√£o de tarefas

### por que makefile?

makefile √© a forma mais simples de documentar e automatizar tarefas comuns. em vez de lembrar comandos longos, voc√™ s√≥ precisa rodar `make up` ou `make test`.

### makefile completo

```makefile
.PHONY: help build up down restart logs shell test clean

# Vari√°veis
COMPOSE_FILE = docker-compose.yml
COMPOSE = docker-compose -f $(COMPOSE_FILE)
DOCKER = docker

# Cores para output
GREEN  := $(shell tput -Txterm setaf 2)
YELLOW := $(shell tput -Txterm setaf 3)
RESET  := $(shell tput -Txterm sgr0)

help: ## Mostra esta mensagem de ajuda
	@echo "$(GREEN)Comandos dispon√≠veis:$(RESET)"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "  $(YELLOW)%-20s$(RESET) %s\n", $$1, $$2}'

build: ## Constr√≥i as imagens Docker
	$(COMPOSE) build

build-no-cache: ## Constr√≥i sem usar cache
	$(COMPOSE) build --no-cache

up: ## Inicia todos os servi√ßos
	$(COMPOSE) up -d

up-build: ## Constr√≥i e inicia servi√ßos
	$(COMPOSE) up -d --build

down: ## Para todos os servi√ßos
	$(COMPOSE) down

down-volumes: ## Para servi√ßos e remove volumes
	$(COMPOSE) down -v

restart: ## Reinicia todos os servi√ßos
	$(COMPOSE) restart

logs: ## Mostra logs de todos os servi√ßos
	$(COMPOSE) logs -f

logs-backend: ## Mostra logs apenas do backend
	$(COMPOSE) logs -f backend

shell: ## Abre shell no container backend
	$(COMPOSE) exec backend bash

shell-db: ## Abre shell no banco de dados
	$(COMPOSE) exec db psql -U $(DB_USER) -d $(DB_NAME)

test: ## Roda testes
	$(COMPOSE) exec backend pytest

test-watch: ## Roda testes em modo watch
	$(COMPOSE) exec backend pytest-watch

migrate: ## Roda migrations
	$(COMPOSE) exec backend python manage.py migrate

makemigrations: ## Cria novas migrations
	$(COMPOSE) exec backend python manage.py makemigrations

collectstatic: ## Coleta arquivos est√°ticos
	$(COMPOSE) exec backend python manage.py collectstatic --noinput

createsuperuser: ## Cria superuser Django
	$(COMPOSE) exec backend python manage.py createsuperuser

clean: ## Remove containers, volumes e imagens n√£o utilizados
	$(DOCKER) system prune -a --volumes -f

clean-all: ## Remove tudo (containers, volumes, imagens, networks)
	$(COMPOSE) down -v --rmi all
	$(DOCKER) system prune -a --volumes -f

ps: ## Lista containers em execu√ß√£o
	$(COMPOSE) ps

status: ## Mostra status dos servi√ßos
	$(COMPOSE) ps
	@echo "\n$(GREEN)Health checks:$(RESET)"
	@$(COMPOSE) ps --format json | jq -r '.[] | "\(.Name): \(.Health)"'

# Desenvolvimento
dev: ## Inicia ambiente de desenvolvimento
	$(COMPOSE) -f docker-compose.yml -f docker-compose.dev.yml up

dev-build: ## Constr√≥i e inicia ambiente de desenvolvimento
	$(COMPOSE) -f docker-compose.yml -f docker-compose.dev.yml up --build

# Produ√ß√£o
prod: ## Inicia ambiente de produ√ß√£o
	$(COMPOSE) -f docker-compose.yml -f docker-compose.prod.yml up -d

prod-build: ## Constr√≥i e inicia ambiente de produ√ß√£o
	$(COMPOSE) -f docker-compose.yml -f docker-compose.prod.yml up -d --build

# Backup e restore
backup-db: ## Faz backup do banco de dados
	$(COMPOSE) exec db pg_dump -U $(DB_USER) $(DB_NAME) > backup_$(shell date +%Y%m%d_%H%M%S).sql

restore-db: ## Restaura banco de dados (use: make restore-db FILE=backup.sql)
	@if [ -z "$(FILE)" ]; then \
		echo "$(YELLOW)Erro: Especifique o arquivo com FILE=backup.sql$(RESET)"; \
		exit 1; \
	fi
	$(COMPOSE) exec -T db psql -U $(DB_USER) -d $(DB_NAME) < $(FILE)
```

### uso do makefile

```bash
# Ver todos os comandos dispon√≠veis
make help

# Iniciar ambiente
make up

# Ver logs
make logs

# Rodar testes
make test

# Abrir shell no container
make shell

# Fazer backup do banco
make backup-db
```

---

## .dockerignore - otimizar builds

criar `.dockerignore` √© essencial para builds r√°pidos:

```
# Git
.git
.gitignore
.gitattributes

# Python
__pycache__
*.pyc
*.pyo
*.pyd
.Python
*.so
*.egg
*.egg-info
dist
build
.eggs

# Virtual environments
venv/
env/
ENV/

# IDEs
.vscode/
.idea/
*.swp
*.swo

# Logs
*.log
logs/

# Environment
.env
.env.local
.env.*.local

# Tests
.pytest_cache/
.coverage
htmlcov/

# Documentation
docs/
*.md
!README.md

# Docker
Dockerfile*
docker-compose*.yml
.dockerignore
```

---

## nginx configuration

### estrutura b√°sica

```nginx
server {
    listen 80;
    server_name example.com;

    location / {
        proxy_pass http://backend:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /static/ {
        alias /app/staticfiles/;
    }

    location /media/ {
        alias /app/media/;
    }
}
```

---

## environment variables

### desenvolvimento

```bash
# .env (gitignored)
DEBUG=True
DATABASE_URL=postgresql://user:pass@localhost/db
SECRET_KEY=dev-secret-key
```

### produ√ß√£o

```bash
# .env.prod (no servidor, n√£o versionado)
DEBUG=False
DATABASE_URL=postgresql://user:realpass@db:5432/prod_db
SECRET_KEY=production-secret-key-from-secrets-manager
```

### carregamento

```python
# sempre usar python-dotenv
from dotenv import load_dotenv
import os

# tentar carregar .env.prod primeiro, depois .env
if os.path.exists('.env.prod'):
    load_dotenv('.env.prod')
else:
    load_dotenv()

DATABASE_URL = os.getenv('DATABASE_URL')
```

---

## deployment process

### staging first

- sempre testar em staging antes de produ√ß√£o
- validar migrations antes de deploy
- ter rollback plan pronto
- monitorar ap√≥s deploy

### checklist de deploy

- [ ] c√≥digo testado em staging
- [ ] migrations validadas
- [ ] environment variables configuradas
- [ ] secrets atualizados
- [ ] backup do banco (se necess√°rio)
- [ ] rollback plan documentado
- [ ] monitoramento ativo

---

## ci/cd pipelines

### estrutura b√°sica

```yaml
# .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run tests
        run: pytest
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Deploy
        run: |
          # deployment commands
```

---

## boas pr√°ticas gerais

### 1. sempre use tags espec√≠ficas

```dockerfile
# ‚ùå ruim - latest pode mudar
FROM python:latest

# ‚úÖ bom - vers√£o espec√≠fica
FROM python:3.11-slim
```

### 2. ordene comandos por frequ√™ncia de mudan√ßa

```dockerfile
# Comandos que mudam pouco primeiro (cache melhor)
FROM python:3.11-slim
RUN apt-get update && apt-get install -y gcc

# Comandos que mudam frequentemente por √∫ltimo
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
```

### 3. use .dockerignore

sem `.dockerignore`, voc√™ copia arquivos desnecess√°rios, aumentando tempo de build e tamanho da imagem.

### 4. healthchecks em todos os servi√ßos

healthchecks permitem que docker saiba quando servi√ßos est√£o realmente prontos:

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  interval: 30s
  timeout: 10s
  retries: 3
```

### 5. restart policies

```yaml
# Sempre reiniciar se falhar
restart: always

# Reiniciar a menos que parado manualmente
restart: unless-stopped

# Nunca reiniciar automaticamente
restart: no
```

### 6. limites de recursos

em produ√ß√£o, sempre defina limites:

```yaml
deploy:
  resources:
    limits:
      cpus: '1.0'
      memory: 512M
    reservations:
      cpus: '0.5'
      memory: 256M
```

---

## troubleshooting

### container n√£o inicia

```bash
# Ver logs
docker-compose logs service-name

# Ver logs em tempo real
docker-compose logs -f service-name

# Entrar no container
docker-compose exec service-name bash
```

### build lento

```bash
# Verificar cache
docker system df

# Limpar cache
docker builder prune

# Build sem cache (para testar)
docker-compose build --no-cache
```

### volumes n√£o funcionam

```bash
# Listar volumes
docker volume ls

# Inspecionar volume
docker volume inspect volume-name

# Remover volume
docker volume rm volume-name
```

---

## refer√™ncias

- cicd agent ‚Üí `../../../agents/cicd-agent.mdc`
- cicd context ‚Üí `../../../../config/cicd/README.md`
- docker best practices ‚Üí se√ß√£o "dockerfile - a base de tudo" acima

---

**estas regras s√£o obrigat√≥rias para todos os deploys.**


