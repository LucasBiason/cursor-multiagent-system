# Estrutura de Projetos Generative AI

**Fonte:** Generative AI Project Structure - Brij Kishore Pandey

Este documento descreve a estrutura recomendada e melhores prÃ¡ticas para projetos de Generative AI, seguindo padrÃµes profissionais de organizaÃ§Ã£o e manutenibilidade.

---

## ğŸ“ Estrutura de DiretÃ³rios

```
generative_ai_project/
â”œâ”€â”€ config/                      # ConfiguraÃ§Ãµes separadas do cÃ³digo
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_config.yaml        # ConfiguraÃ§Ãµes de modelos
â”‚   â”œâ”€â”€ prompt_templates.yaml    # Templates de prompts
â”‚   â””â”€â”€ logging_config.yaml      # ConfiguraÃ§Ãµes de logging
â”‚
â”œâ”€â”€ src/                         # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ llm/                     # Clientes LLM
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # Classe base abstrata
â”‚   â”‚   â”œâ”€â”€ claude_client.py     # Cliente Claude
â”‚   â”‚   â”œâ”€â”€ gpt_client.py        # Cliente GPT
â”‚   â”‚   â””â”€â”€ utils.py              # UtilitÃ¡rios LLM
â”‚   â”‚
â”‚   â”œâ”€â”€ prompt_engineering/      # Engenharia de prompts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ templates.py         # Templates de prompts
â”‚   â”‚   â”œâ”€â”€ few_shot.py          # Exemplos few-shot
â”‚   â”‚   â””â”€â”€ chainer.py           # Encadeamento de prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # UtilitÃ¡rios gerais
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py      # Rate limiting para APIs
â”‚   â”‚   â”œâ”€â”€ token_counter.py     # Contagem de tokens
â”‚   â”‚   â”œâ”€â”€ cache.py             # Sistema de cache
â”‚   â”‚   â””â”€â”€ logger.py            # Sistema de logging
â”‚   â”‚
â”‚   â””â”€â”€ handlers/                # Handlers de erro
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ error_handler.py     # Tratamento de erros
â”‚
â”œâ”€â”€ data/                        # Dados organizados
â”‚   â”œâ”€â”€ cache/                   # Cache de respostas
â”‚   â”œâ”€â”€ prompts/                  # Prompts armazenados
â”‚   â”œâ”€â”€ outputs/                 # SaÃ­das geradas
â”‚   â””â”€â”€ embeddings/               # Embeddings armazenados
â”‚
â”œâ”€â”€ examples/                    # Exemplos de uso
â”‚   â”œâ”€â”€ basic_completion.py      # Exemplo bÃ¡sico
â”‚   â”œâ”€â”€ chat_session.py          # SessÃ£o de chat
â”‚   â””â”€â”€ chain_prompts.py         # Encadeamento de prompts
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â”œâ”€â”€ prompt_testing.ipynb     # Testes de prompts
â”‚   â”œâ”€â”€ response_analysis.ipynb  # AnÃ¡lise de respostas
â”‚   â””â”€â”€ model_experimentation.ipynb  # ExperimentaÃ§Ã£o
â”‚
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ setup.py                     # Setup do projeto
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o principal
â””â”€â”€ Dockerfile                   # ContainerizaÃ§Ã£o
```

---

## ğŸ¯ Componentes Principais

### `config/` - ConfiguraÃ§Ãµes

**PropÃ³sito:** Separar configuraÃ§Ãµes do cÃ³digo, facilitando manutenÃ§Ã£o e deploy.

**Arquivos:**
- `model_config.yaml`: ConfiguraÃ§Ãµes de modelos (temperatura, max_tokens, etc.)
- `prompt_templates.yaml`: Templates de prompts reutilizÃ¡veis
- `logging_config.yaml`: ConfiguraÃ§Ãµes de logging

**BenefÃ­cios:**
- âœ… FÃ¡cil alteraÃ§Ã£o sem modificar cÃ³digo
- âœ… Suporte a mÃºltiplos ambientes (dev, prod)
- âœ… Versionamento de configuraÃ§Ãµes

### `src/` - CÃ³digo Fonte

**PropÃ³sito:** CÃ³digo modular e organizado por responsabilidade.

#### `llm/` - Clientes LLM

- **`base.py`**: Interface abstrata para todos os clientes LLM
- **`claude_client.py`**: ImplementaÃ§Ã£o especÃ­fica do Claude
- **`gpt_client.py`**: ImplementaÃ§Ã£o especÃ­fica do GPT
- **`utils.py`**: FunÃ§Ãµes auxiliares (formataÃ§Ã£o, validaÃ§Ã£o)

**PadrÃ£o:** Cada cliente implementa a interface base, garantindo consistÃªncia.

#### `prompt_engineering/` - Engenharia de Prompts

- **`templates.py`**: Templates reutilizÃ¡veis de prompts
- **`few_shot.py`**: Gerenciamento de exemplos few-shot
- **`chainer.py`**: Encadeamento de prompts para fluxos complexos

**BenefÃ­cios:**
- âœ… ReutilizaÃ§Ã£o de prompts
- âœ… ConsistÃªncia na geraÃ§Ã£o
- âœ… FÃ¡cil experimentaÃ§Ã£o

#### `utils/` - UtilitÃ¡rios

- **`rate_limiter.py`**: Controle de taxa de requisiÃ§Ãµes
- **`token_counter.py`**: Contagem e otimizaÃ§Ã£o de tokens
- **`cache.py`**: Cache de respostas para reduzir custos
- **`logger.py`**: Sistema de logging padronizado

#### `handlers/` - Tratamento de Erros

- **`error_handler.py`**: Tratamento centralizado de erros

### `data/` - Dados

**OrganizaÃ§Ã£o por tipo:**
- `cache/`: Respostas em cache
- `prompts/`: Prompts salvos
- `outputs/`: SaÃ­das geradas
- `embeddings/`: Embeddings prÃ©-computados

### `examples/` - Exemplos

CÃ³digo de exemplo demonstrando uso do framework:
- Exemplos bÃ¡sicos
- Casos de uso avanÃ§ados
- PadrÃµes de uso

### `notebooks/` - ExperimentaÃ§Ã£o

Jupyter notebooks para:
- Testes de prompts
- AnÃ¡lise de respostas
- ExperimentaÃ§Ã£o com modelos

---

## âœ… Melhores PrÃ¡ticas

### 1. Use YAML para ConfiguraÃ§Ãµes

**Por quÃª:**
- FÃ¡cil de ler e editar
- Suporta estruturas complexas
- PadrÃ£o da indÃºstria

**Exemplo:**
```yaml
# model_config.yaml
models:
  gpt4:
    temperature: 0.7
    max_tokens: 2000
  claude:
    temperature: 0.5
    max_tokens: 1500
```

### 2. Implemente Tratamento de Erros Adequado

**Por quÃª:**
- APIs podem falhar
- Rate limits podem ser atingidos
- Respostas podem ser invÃ¡lidas

**Exemplo:**
```python
try:
    response = llm_client.generate(prompt)
except RateLimitError:
    # Retry com backoff
except APIError as e:
    # Log e notificar
```

### 3. Use Rate Limiting para APIs

**Por quÃª:**
- Evita exceder limites da API
- Reduz custos
- Melhora confiabilidade

**ImplementaÃ§Ã£o:**
- Decorators para rate limiting
- Filas para requisiÃ§Ãµes
- Retry com backoff exponencial

### 4. Separe Clientes de Modelos

**Por quÃª:**
- Facilita troca de modelos
- Permite usar mÃºltiplos modelos
- Testes mais fÃ¡ceis

**PadrÃ£o:**
```python
class BaseLLMClient(ABC):
    @abstractmethod
    def generate(self, prompt: str) -> str:
        pass

class GPTClient(BaseLLMClient):
    def generate(self, prompt: str) -> str:
        # ImplementaÃ§Ã£o GPT
```

### 5. Cache Resultados Apropriadamente

**Por quÃª:**
- Reduz custos de API
- Melhora performance
- Permite reprocessamento

**EstratÃ©gias:**
- Cache por hash do prompt
- TTL configurÃ¡vel
- InvalidaÃ§Ã£o inteligente

### 6. Mantenha DocumentaÃ§Ã£o Atualizada

**Por quÃª:**
- Facilita onboarding
- Reduz perguntas
- Melhora manutenibilidade

**Documentar:**
- README com exemplos
- Docstrings em funÃ§Ãµes
- ComentÃ¡rios em cÃ³digo complexo

### 7. Use Notebooks para Testes

**Por quÃª:**
- ExperimentaÃ§Ã£o rÃ¡pida
- VisualizaÃ§Ã£o de resultados
- DocumentaÃ§Ã£o interativa

---

## ğŸš€ Como ComeÃ§ar

### Passo 1: Clone o RepositÃ³rio

```bash
git clone <repository-url>
cd generative_ai_project
```

### Passo 2: Instale DependÃªncias

```bash
pip install -r requirements.txt
```

### Passo 3: Configure Modelos

Edite `config/model_config.yaml` com suas configuraÃ§Ãµes:
- API keys
- Modelos preferidos
- ParÃ¢metros padrÃ£o

### Passo 4: Revise Exemplos

Explore `examples/` para entender o uso:
- `basic_completion.py`: Uso bÃ¡sico
- `chat_session.py`: SessÃµes de chat
- `chain_prompts.py`: Encadeamento

### Passo 5: Comece com Notebooks

Use `notebooks/` para experimentar:
- Testar prompts
- Analisar respostas
- Experimentar modelos

---

## ğŸ’¡ Dicas de Desenvolvimento

### 1. Siga Design Modular

- Separe responsabilidades
- Use interfaces abstratas
- Facilite testes unitÃ¡rios

### 2. Escreva Testes de Componentes

- Teste cada mÃ³dulo isoladamente
- Use mocks para APIs externas
- Mantenha cobertura alta

### 3. Use Controle de VersÃ£o

- Commits frequentes
- Mensagens descritivas
- Branches para features

### 4. Mantenha Docs Atualizadas

- Atualize README
- Documente mudanÃ§as
- Adicione exemplos

### 5. Monitore Uso de API

- Track de custos
- Monitore rate limits
- Analise performance

---

## ğŸ“„ Arquivos Principais

### `requirements.txt`

Lista todas as dependÃªncias do projeto:
```txt
openai>=1.0.0
anthropic>=0.5.0
pyyaml>=6.0
requests>=2.31.0
```

### `README.md`

DocumentaÃ§Ã£o principal do projeto:
- VisÃ£o geral
- InstalaÃ§Ã£o
- Exemplos de uso
- ContribuiÃ§Ã£o

### `Dockerfile`

ContainerizaÃ§Ã£o para deploy:
- Ambiente isolado
- Reproducibilidade
- Facilita deploy

---

## ğŸ”„ AplicaÃ§Ã£o no Diagram Generator

Esta estrutura foi aplicada no projeto `diagram-generator`:

```
diagram-generator/
â”œâ”€â”€ prompt_engineering/          # âœ… Implementado
â”‚   â”œâ”€â”€ base.py                 # Classes base
â”‚   â”œâ”€â”€ chainer.py              # Encadeamento
â”‚   â”œâ”€â”€ few_shot.py             # Few-shot examples
â”‚   â””â”€â”€ templates/             # Templates especÃ­ficos
â”‚       â””â”€â”€ diagram_base.py    # Template base
â”‚
â”œâ”€â”€ generators/                 # Clientes de geraÃ§Ã£o
â”‚   â”œâ”€â”€ base.py                 # Interface base
â”‚   â”œâ”€â”€ gemini.py              # Cliente Gemini
â”‚   â””â”€â”€ openai_dalle.py        # Cliente DALL-E
â”‚
â””â”€â”€ config.py                  # ConfiguraÃ§Ãµes
```

---

**Ãšltima AtualizaÃ§Ã£o:** 2025-12-10  
**Fonte:** Generative AI Project Structure - Brij Kishore Pandey

